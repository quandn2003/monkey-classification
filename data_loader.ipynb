{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import os\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['n0', 'n1', 'n2', 'n3', 'n4', 'n5', 'n6', 'n7', 'n8', 'n9']"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"./training/training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_path = './training/training'\n",
    "test_dataset_path = './validation/validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result from mean_std.ipynb: \n",
    "# (mean, std) = (tensor([0.4363, 0.4328, 0.3291]), tensor([0.2129, 0.2075, 0.2038]))\n",
    "mean = [0.4363, 0.4328, 0.3291]\n",
    "std = [0.2129, 0.2075, 0.2038]\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), \n",
    "    # transforms.CenterCrop((10, 20)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(torch.Tensor(mean), torch.Tensor(std))\n",
    "])\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(torch.Tensor(mean), torch.Tensor(std))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.ImageFolder(root = train_dataset_path, transform = train_transforms)\n",
    "test_dataset = torchvision.datasets.ImageFolder(root = test_dataset_path, transform = test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 224, 224]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(dataset = train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset = test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "images, labels = batch\n",
    "print(images.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_transformed_images(dataset):\n",
    "    batch = next(iter(DataLoader(dataset, batch_size=12, shuffle=True)))\n",
    "    images, labels = batch\n",
    "     \n",
    "    grid = torchvision.utils.make_grid(images, nrow=3)\n",
    "    plt.figure(figsize=(11, 11))\n",
    "    plt.imshow(np.transpose(grid, (1, 2 , 0)))\n",
    "    print('labels: ', labels)\n",
    "# example_transformed_images(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_device():\n",
    "    if torch.cuda.is_available():\n",
    "        dev = \"cuda:0\"\n",
    "    else:\n",
    "        dev = \"cpu\"\n",
    "    return torch.device(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(model, train_loader, test_loader, criterion, optimizer, n_epochs):\n",
    "    device = set_device()\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        print(\"Epoch number %d \" %(epoch+1))\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_correct = 0.0\n",
    "        total = 0\n",
    "        \n",
    "        for data in train_loader:\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            total += labels.size(0)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(images)\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "              \n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            running_correct += (labels==predicted).sum().item()\n",
    "        \n",
    "        epoch_loss = running_loss/len(train_loader)\n",
    "        epoch_acc = 100.00 * running_correct / total\n",
    "        \n",
    "        # print(f'      -Training dataset. Got {running_correct} out of {total} images correctly ({epoch_acc}). Epoch loss: {epoch_loss}')\n",
    "        print('      -Training dataset. Got %d out of %d images correctly (%.3f%%). Epoch loss: %.3f%%' \n",
    "                %(running_correct, total, epoch_acc, epoch_loss))\n",
    "        \n",
    "        evaluate_model(model, test_loader)\n",
    "        \n",
    "    print('Finish')\n",
    "    \n",
    "    return model\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    \n",
    "    predicted_correctly_on_epoch = 0\n",
    "    total = 0\n",
    "    device = set_device()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            total += labels.size(0)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            predicted_correctly_on_epoch += (predicted == labels).sum().item()\n",
    "    \n",
    "    epoch_acc = 100.00 * predicted_correctly_on_epoch / total\n",
    "    print('      -Testing dataset. Got %d out of %d images correctly (%.3f%%)' \n",
    "          %(predicted_correctly_on_epoch, total, epoch_acc))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "resnet18_model = models.resnet18(pretrained=True)\n",
    "num_features = resnet18_model.fc.in_features\n",
    "number_of_classes = 10\n",
    "resnet18_model.fc = nn.Linear(num_features, number_of_classes)\n",
    "device = set_device()\n",
    "resnet_18_model = resnet18_model.to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(resnet18_model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number 1 \n",
      "      -Training dataset. Got 1096 out of 1097 images correctly (99.909%). Epoch loss: 0.011%\n",
      "      -Testing dataset. Got 241 out of 272 images correctly (88.603%)\n",
      "Epoch number 2 \n",
      "      -Training dataset. Got 1089 out of 1097 images correctly (99.271%). Epoch loss: 0.037%\n",
      "      -Testing dataset. Got 227 out of 272 images correctly (83.456%)\n",
      "Epoch number 3 \n",
      "      -Training dataset. Got 1095 out of 1097 images correctly (99.818%). Epoch loss: 0.025%\n",
      "      -Testing dataset. Got 233 out of 272 images correctly (85.662%)\n",
      "Epoch number 4 \n",
      "      -Training dataset. Got 1097 out of 1097 images correctly (100.000%). Epoch loss: 0.012%\n",
      "      -Testing dataset. Got 237 out of 272 images correctly (87.132%)\n",
      "Epoch number 5 \n",
      "      -Training dataset. Got 1097 out of 1097 images correctly (100.000%). Epoch loss: 0.010%\n",
      "      -Testing dataset. Got 239 out of 272 images correctly (87.868%)\n",
      "Epoch number 6 \n",
      "      -Training dataset. Got 1096 out of 1097 images correctly (99.909%). Epoch loss: 0.014%\n",
      "      -Testing dataset. Got 240 out of 272 images correctly (88.235%)\n",
      "Epoch number 7 \n",
      "      -Training dataset. Got 1095 out of 1097 images correctly (99.818%). Epoch loss: 0.024%\n",
      "      -Testing dataset. Got 236 out of 272 images correctly (86.765%)\n",
      "Epoch number 8 \n",
      "      -Training dataset. Got 1095 out of 1097 images correctly (99.818%). Epoch loss: 0.018%\n",
      "      -Testing dataset. Got 235 out of 272 images correctly (86.397%)\n",
      "Epoch number 9 \n",
      "      -Training dataset. Got 1096 out of 1097 images correctly (99.909%). Epoch loss: 0.015%\n",
      "      -Testing dataset. Got 246 out of 272 images correctly (90.441%)\n",
      "Epoch number 10 \n",
      "      -Training dataset. Got 1086 out of 1097 images correctly (98.997%). Epoch loss: 0.044%\n",
      "      -Testing dataset. Got 229 out of 272 images correctly (84.191%)\n",
      "Epoch number 11 \n",
      "      -Training dataset. Got 1084 out of 1097 images correctly (98.815%). Epoch loss: 0.051%\n",
      "      -Testing dataset. Got 230 out of 272 images correctly (84.559%)\n",
      "Epoch number 12 \n",
      "      -Training dataset. Got 1087 out of 1097 images correctly (99.088%). Epoch loss: 0.064%\n",
      "      -Testing dataset. Got 231 out of 272 images correctly (84.926%)\n",
      "Epoch number 13 \n",
      "      -Training dataset. Got 1092 out of 1097 images correctly (99.544%). Epoch loss: 0.036%\n",
      "      -Testing dataset. Got 238 out of 272 images correctly (87.500%)\n",
      "Epoch number 14 \n",
      "      -Training dataset. Got 1096 out of 1097 images correctly (99.909%). Epoch loss: 0.025%\n",
      "      -Testing dataset. Got 237 out of 272 images correctly (87.132%)\n",
      "Epoch number 15 \n",
      "      -Training dataset. Got 1092 out of 1097 images correctly (99.544%). Epoch loss: 0.041%\n",
      "      -Testing dataset. Got 237 out of 272 images correctly (87.132%)\n",
      "Epoch number 16 \n",
      "      -Training dataset. Got 1088 out of 1097 images correctly (99.180%). Epoch loss: 0.048%\n",
      "      -Testing dataset. Got 231 out of 272 images correctly (84.926%)\n",
      "Epoch number 17 \n",
      "      -Training dataset. Got 1046 out of 1097 images correctly (95.351%). Epoch loss: 0.195%\n",
      "      -Testing dataset. Got 158 out of 272 images correctly (58.088%)\n",
      "Epoch number 18 \n",
      "      -Training dataset. Got 1025 out of 1097 images correctly (93.437%). Epoch loss: 0.215%\n",
      "      -Testing dataset. Got 211 out of 272 images correctly (77.574%)\n",
      "Epoch number 19 \n",
      "      -Training dataset. Got 1060 out of 1097 images correctly (96.627%). Epoch loss: 0.113%\n",
      "      -Testing dataset. Got 231 out of 272 images correctly (84.926%)\n",
      "Epoch number 20 \n",
      "      -Training dataset. Got 1087 out of 1097 images correctly (99.088%). Epoch loss: 0.053%\n",
      "      -Testing dataset. Got 224 out of 272 images correctly (82.353%)\n",
      "Finish\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_nn(resnet18_model, train_loader, test_loader, loss_fn, optimizer, 20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
